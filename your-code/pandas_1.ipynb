{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPs1CnOFnJlW"
      },
      "source": [
        "# Introduction to Pandas Lab\n",
        "\n",
        "Complete the following set of exercises to solidify your knowledge of Pandas fundamentals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neh17PDAnJlZ"
      },
      "source": [
        "### 1. Import Numpy and Pandas and alias them to `np` and `pd` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGFmVUN3nJlZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU-rWdm_nJlb"
      },
      "source": [
        "### 2. Create a Pandas Series containing the elements of the list below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw5Oj5bBnJlc"
      },
      "outputs": [],
      "source": [
        "lst = [5.7, 75.2, 74.4, 84.0, 66.5, 66.3, 55.8, 75.7, 29.1, 43.7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip7pM0fUnJld",
        "outputId": "32edd14a-8d8e-4927-bbc4-cf21ce4694d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     5.7\n",
            "1    75.2\n",
            "2    74.4\n",
            "3    84.0\n",
            "4    66.5\n",
            "5    66.3\n",
            "6    55.8\n",
            "7    75.7\n",
            "8    29.1\n",
            "9    43.7\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "series = pd.Series(lst)\n",
        "\n",
        "print(series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsPEJfv4nJld"
      },
      "source": [
        "### 3. Use indexing to return the third value in the Series above.\n",
        "\n",
        "*Hint: Remember that indexing begins at 0.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSoqMsIKnJle",
        "outputId": "3b7fc0db-d733-409b-d11c-68e8611fbb7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74.4\n"
          ]
        }
      ],
      "source": [
        "third_value = series[2]\n",
        "\n",
        "print(third_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCJUl8CrnJle"
      },
      "source": [
        "### 4. Create a Pandas DataFrame from the list of lists below. Each sublist should be represented as a row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0drwbAvnJle"
      },
      "outputs": [],
      "source": [
        "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
        "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
        "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
        "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
        "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
        "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
        "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
        "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
        "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
        "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09j4F4t_nJlf",
        "outputId": "d7cf8eb7-f96f-4fd3-f36d-f03d64092d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0     1     2     3     4\n",
            "0  53.1  95.0  67.5  35.0  78.4\n",
            "1  61.3  40.8  30.8  37.8  87.6\n",
            "2  20.6  73.2  44.2  14.6  91.8\n",
            "3  57.4   0.1  96.1   4.2  69.5\n",
            "4  83.6  20.5  85.4  22.8  35.9\n",
            "5  49.0  69.0   0.1  31.8  89.1\n",
            "6  23.3  40.7  95.0  83.8  26.9\n",
            "7  27.6  26.4  53.8  88.8  68.5\n",
            "8  96.6  96.4  53.4  72.4  50.1\n",
            "9  73.7  39.0  43.2  81.6  34.7\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(b)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fErQLnSznJlf"
      },
      "source": [
        "### 5. Rename the data frame columns based on the names in the list below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksCQ_JdPnJlf"
      },
      "outputs": [],
      "source": [
        "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
        "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
        "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
        "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
        "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
        "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
        "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
        "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
        "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
        "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_G8ozlHnJlg",
        "outputId": "fbf94bd8-1365-492f-f345-067f9f3a26cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      A     B     C     D     E\n",
            "0  53.1  95.0  67.5  35.0  78.4\n",
            "1  61.3  40.8  30.8  37.8  87.6\n",
            "2  20.6  73.2  44.2  14.6  91.8\n",
            "3  57.4   0.1  96.1   4.2  69.5\n",
            "4  83.6  20.5  85.4  22.8  35.9\n",
            "5  49.0  69.0   0.1  31.8  89.1\n",
            "6  23.3  40.7  95.0  83.8  26.9\n",
            "7  27.6  26.4  53.8  88.8  68.5\n",
            "8  96.6  96.4  53.4  72.4  50.1\n",
            "9  73.7  39.0  43.2  81.6  34.7\n"
          ]
        }
      ],
      "source": [
        "f = pd.DataFrame(b)\n",
        "new_column_names = ['A', 'B', 'C', 'D', 'E']\n",
        "df.columns = new_column_names\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzIu5ZXLnJlg"
      },
      "source": [
        "### 6. Create a subset of this data frame that contains only the Score 1, 3, and 5 columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5VaGhlPnJlg",
        "outputId": "f1591398-dccf-4146-b104-2969659ff34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Score 1  Score 3  Score 5\n",
            "0     53.1     67.5     78.4\n",
            "1     61.3     30.8     87.6\n",
            "2     20.6     44.2     91.8\n",
            "3     57.4     96.1     69.5\n",
            "4     83.6     85.4     35.9\n",
            "5     49.0      0.1     89.1\n",
            "6     23.3     95.0     26.9\n",
            "7     27.6     53.8     68.5\n",
            "8     96.6     53.4     50.1\n",
            "9     73.7     43.2     34.7\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(b, columns=['Score 1', 'Score 2', 'Score 3', 'Score 4', 'Score 5'])\n",
        "subset_df = df[['Score 1', 'Score 3', 'Score 5']]\n",
        "print(subset_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxdiz3iSnJlg"
      },
      "source": [
        "### 7. From the original data frame, calculate the average Score_3 value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oua60J4KnJlh",
        "outputId": "0ea7f371-2874-482b-def3-1ef151bd7b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average Score 3 value is: 56.95000000000001\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(b, columns=['Score 1', 'Score 2', 'Score 3', 'Score 4', 'Score 5'])\n",
        "average_score_3 = df['Score 3'].mean()\n",
        "print(f\"The average Score 3 value is: {average_score_3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cuumt-ZnJlh"
      },
      "source": [
        "### 8. From the original data frame, calculate the maximum Score_4 value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnZnPNdOnJlh",
        "outputId": "803abc67-5837-4425-ae8e-22e311f0d4a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum Score 4 value is: 88.8\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(b, columns=['Score 1', 'Score 2', 'Score 3', 'Score 4', 'Score 5'])\n",
        "\n",
        "max_score_4 = df['Score 4'].max()\n",
        "print(f\"The maximum Score 4 value is: {max_score_4}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DVH4bVGnJli"
      },
      "source": [
        "### 9. From the original data frame, calculate the median Score 2 value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1VaW0PgnJli",
        "outputId": "49c8bc6b-37cb-43d1-a94e-54593b729667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The median Score 2 value is: 40.75\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(b, columns=['Score 1', 'Score 2', 'Score 3', 'Score 4', 'Score 5'])\n",
        "\n",
        "median_score_2 = df['Score 2'].median()\n",
        "print(f\"The median Score 2 value is: {median_score_2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHBrK2nPnJli"
      },
      "source": [
        "### 10. Create a Pandas DataFrame from the dictionary of product orders below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csLslnMJnJli"
      },
      "outputs": [],
      "source": [
        "orders = {'Description': ['LUNCH BAG APPLE DESIGN',\n",
        "  'SET OF 60 VINTAGE LEAF CAKE CASES ',\n",
        "  'RIBBON REEL STRIPES DESIGN ',\n",
        "  'WORLD WAR 2 GLIDERS ASSTD DESIGNS',\n",
        "  'PLAYING CARDS JUBILEE UNION JACK',\n",
        "  'POPCORN HOLDER',\n",
        "  'BOX OF VINTAGE ALPHABET BLOCKS',\n",
        "  'PARTY BUNTING',\n",
        "  'JAZZ HEARTS ADDRESS BOOK',\n",
        "  'SET OF 4 SANTA PLACE SETTINGS'],\n",
        " 'Quantity': [1, 24, 1, 2880, 2, 7, 1, 4, 10, 48],\n",
        " 'UnitPrice': [1.65, 0.55, 1.65, 0.18, 1.25, 0.85, 11.95, 4.95, 0.19, 1.25],\n",
        " 'Revenue': [1.65, 13.2, 1.65, 518.4, 2.5, 5.95, 11.95, 19.8, 1.9, 60.0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5mM9NZZnJlj",
        "outputId": "55c7e65c-4661-4734-f14a-0f5416e24273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Description  Quantity  UnitPrice  Revenue\n",
            "0              LUNCH BAG APPLE DESIGN         1       1.65     1.65\n",
            "1  SET OF 60 VINTAGE LEAF CAKE CASES         24       0.55    13.20\n",
            "2         RIBBON REEL STRIPES DESIGN          1       1.65     1.65\n",
            "3   WORLD WAR 2 GLIDERS ASSTD DESIGNS      2880       0.18   518.40\n",
            "4    PLAYING CARDS JUBILEE UNION JACK         2       1.25     2.50\n",
            "5                      POPCORN HOLDER         7       0.85     5.95\n",
            "6      BOX OF VINTAGE ALPHABET BLOCKS         1      11.95    11.95\n",
            "7                       PARTY BUNTING         4       4.95    19.80\n",
            "8            JAZZ HEARTS ADDRESS BOOK        10       0.19     1.90\n",
            "9       SET OF 4 SANTA PLACE SETTINGS        48       1.25    60.00\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(orders)\n",
        "\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRKLn66LnJlj"
      },
      "source": [
        "### 11. Calculate the total quantity ordered and revenue generated from these orders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nWw6VUtnJlj",
        "outputId": "1c270ea2-76a4-434c-da12-b27067d0ef22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Quantity Ordered: 2978\n",
            "Total Revenue Generated: 637.0\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(orders)\n",
        "\n",
        "\n",
        "total_quantity = df['Quantity'].sum()\n",
        "\n",
        "total_revenue = df['Revenue'].sum()\n",
        "\n",
        "print(f\"Total Quantity Ordered: {total_quantity}\")\n",
        "print(f\"Total Revenue Generated: {total_revenue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu-q9R2gnJlj"
      },
      "source": [
        "### 12. Obtain the prices of the most expensive and least expensive items ordered and print the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJBMvvlNnJlk",
        "outputId": "41f57261-5565-45d9-c812-bb5940d39931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Expensive Item Price: 11.95\n",
            "Least Expensive Item Price: 0.18\n",
            "Difference Between Most and Least Expensive Prices: 11.77\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(orders)\n",
        "\n",
        "\n",
        "most_expensive = df['UnitPrice'].max()\n",
        "least_expensive = df['UnitPrice'].min()\n",
        "\n",
        "\n",
        "price_difference = most_expensive - least_expensive\n",
        "\n",
        "\n",
        "print(f\"Most Expensive Item Price: {most_expensive}\")\n",
        "print(f\"Least Expensive Item Price: {least_expensive}\")\n",
        "print(f\"Difference Between Most and Least Expensive Prices: {price_difference}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk-BgbH0nJlk"
      },
      "source": [
        "## Let's load another dataset for more exercisesÂº"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "R4RBaSVdnJlk",
        "outputId": "3aa617e2-2222-4be4-c3d3-d05724562e85"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../Admission_Predict.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-416c179774b8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run this code:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madmissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Admission_Predict.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Admission_Predict.csv'"
          ]
        }
      ],
      "source": [
        "# Run this code:\n",
        "admissions = pd.read_csv('../Admission_Predict.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIEVbfxonJll"
      },
      "source": [
        "Let's evaluate the dataset by looking at the `head` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi_44D-6nJll"
      },
      "outputs": [],
      "source": [
        "pd.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-TxtBcUnJlm"
      },
      "source": [
        "### 1 - Before beginning to work with this dataset and evaluating graduate admissions data, we will verify that there is no missing data in the dataset. Do this in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMY2_SqtnJlm"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4nnFwMvnJlm"
      },
      "source": [
        "###  2 -  Interestingly, there is a column that uniquely identifies the applicants. This column is the serial number column. Instead of having our own index, we should make this column our index. Do this in the cell below. Keep the column in the dataframe in addition to making it an index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQSbGD6znJlm"
      },
      "outputs": [],
      "source": [
        "df.set_index('Serial Number', drop=False, inplace=True)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vInF_dFvnJln"
      },
      "source": [
        "Turns out that `GRE Score` and `CGPA` also uniquely identify the data. Show this in the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Q8ldu-nJln"
      },
      "source": [
        "### 3 - In this part of the lab, we would like to test complex conditions on the entire data set at once. Let's start by finding the number of rows where the CGPA is greater than 9 and the student has performed an investigation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_MvX-uGinJl7"
      },
      "outputs": [],
      "source": [
        "\n",
        "filtered_rows = df[(df['CGPA'] > 9) & (df['Research'] == 1)]\n",
        "num_rows = len(filtered_rows)\n",
        "\n",
        "print(f\"Number of rows where CGPA > 9 and Research == 1: {num_rows}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTYJqCawnJl8"
      },
      "source": [
        "### 4 - Now return all the rows where the CGPA is greater than 9 and the SOP score is less than 3.5. Find the mean chance of admit for these applicants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0hxRhInnJl8"
      },
      "outputs": [],
      "source": [
        "\n",
        "filtered_rows = df[(df['CGPA'] > 9) & (df['SOP'] < 3.5)]\n",
        "print(\"Filtered Rows:\")\n",
        "print(filtered_rows)\n",
        "mean_chance_of_admit = filtered_rows['Chance of Admit'].mean()\n",
        "print(f\"\\nMean Chance of Admit for applicants with CGPA > 9 and SOP < 3.5: {mean_chance_of_admit:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": "",
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}